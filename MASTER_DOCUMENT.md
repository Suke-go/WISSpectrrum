# マスタードキュメント: 論文探索支援ワークフロー

## 1. 体験のゴール
- ユーザが気になる論文を中心に据え、似ている・少し離れている・まったく異なる研究を直感的に見つけ出せること。
- 論文ごとの「問題意識」「目的」「実装や新規性」「評価方法」を短時間で把握できる要約を提供すること。
- 同じ研究領域や概念（ACM CCS）でのつながりと、意味内容に基づく距離（埋め込み類似度）の両方を切り替えられる、調整可能で楽しい UI を実現すること。
- インタラクション研究者が「まだ語られていない/カバーされていないスコープ」を探り、新しい問いを立てたくなる発見体験を支えること。

## 2. ワークフロー全体像
1. **PDF 収集**: 対象となる論文 PDF をまとめて取得し、決めたディレクトリ構造で保存する。
2. **テキスト抽出**: PDF から構造化されたテキストを取り出し、失敗時には再試行や代替手段を用意する。
3. **要約生成**: 抽出テキストをもとに AI が論文の主要ポイントをセクション別（問題意識 / 目的 / 実装・新規性 / 評価）に要約する。
4. **埋め込み計算**: 要約済みテキストを Gemini Embedding Model でベクトル化し、意味的な近さを計測できるようにする。
5. **ACM CCS 分類**: 事前にパースした ACM CCS タクソノミーを手がかりに、LLM が論文を概念カテゴリへ紐付ける。
6. **類似度計算と可視化**: 全体およびセクション単位の埋め込み類似度、CCS 概念を組み合わせて UI 上で論文を探索できるようにする。

## 3. 工程ごとの要件

### 3.1 PDF 収集と管理
- 入手対象を定義し、収集したファイルは `thesis/<venue>/<year>/` のような一貫したパスで管理する。
- 収集スクリプト（例: `Pre-Processing/scraipingpdf/`）を利用し、サーバへの負荷・利用規約に配慮したダウンロードポリシーを守る。
- メタデータ（タイトル、著者、入手元 URL など）を CSV などで保持して後続処理と紐付ける。

### 3.2 テキスト抽出
- 基本は GROBID を利用し、段落・セクション情報を含む構造化テキストを得る。
- GROBID が利用できない場合は PyPDF などのフォールバックを用意し、抽出品質の差をログに残す。
- 抽出失敗時にはリトライ回数・タイムアウト・エラーレポートを設定し、再実行時の手がかりにする。

### 3.3 セクション別要約生成
- `Pre-Processing/summary/summarize_pdf.py` を通じて、環境変数 (.env) に保存した API キーで OpenAI Responses API を呼び出す。本文は 2,500 文字前後でチャンク化し、250 文字程度のオーバーラップを設けて文脈が途切れないようにする。
- セクション別プロンプトでは「問題意識」「目的」「実装・新規性」「評価」を明示し、Few-shot 例と語数上限（各 2〜3 文）を指定する。生成結果が空や冗長な場合は自動再試行し、最大試行回数を決める。
- 出力 JSON には少なくとも以下を含める: `id`, `title`, `authors`, `abstract`, `positioning`, `purpose`, `method`, `evaluation`, `links`, `embedding_meta`（後段処理用）。欠損情報は `"Not specified"` などの明示メッセージを入れる。
- 生成直後に基本バリデーション（文字数、NG ワード、マークダウン崩れ等）を実施し、失敗したセクションのみを再プロンプトする。処理履歴は `processing_jobs` テーブルにジョブ単位で記録する。
- 実行ログ（API 呼び出しの成否、警告、処理時間、使用トークン数）を構造化ログとして残し、再現性やコスト分析に使えるようにする。

### 3.4 埋め込み計算
- Gemini Embedding API（例: `models/text-embedding-004`）を標準とし、要約 JSON 内の各セクションからベクトルを生成・保存する。処理の入口は専用 CLI / バッチスクリプト `compute_embeddings.py` を用意し、要約済み JSON 群を一括投入する。
- 事前に `GEMINI_API_KEY` を `.env` に設定し、HTTP クライアントまたは公式 SDK（Python, Node.js など）から `content` にセクションテキストを渡して `embedding` を取得する。`task_type="SEMANTIC_SIMILARITY"` を付与し、テキスト長が上限 30k tokens を超えないように自動カットする。
- 取得したベクトルは正規化前の値を `embeddings` テーブルに書き込み、同時に `model`, `embedding_version`, `dim`, `normalized=False`, `created_at`, `source_summary_id` を記録する。コサイン類似度計算時にアプリケーション側または pgvector の `vector_normalize` 関数で正規化する。
- 大量処理では最大 32 件/リクエストを目安にバッチ化し、指数バックオフ + ジッターを備えたリトライ、サーキットブレーカ、レートメーターを導入する。未処理レコードは `processing_jobs` にキューイングし、完了したら `last_embedding_at` を更新する。
- キャッシュ更新ポリシー: 手動で再生成したい場合は `force=true` フラグで既存ベクトルを上書きし、旧バージョンは履歴テーブル（`embeddings_history`）に退避する。
- 参考用フォールバックとして、`sentence-transformers/all-mpnet-base-v2`（ローカル推論・768 次元）、`text-embedding-3-large`（OpenAI, 3,072 次元）、Vertex AI `text-embedding-005` を用意する。フォールバック実行時は `provider`, `cost_estimate`, `latency_ms` をメタ情報に含め、後段でモデル混在を識別できるようにする。
- 例: Python SDK を用いたセクション埋め込み取得
  ```python
  import os
  import google.generativeai as genai

  genai.configure(api_key=os.environ["GEMINI_API_KEY"])

  result = genai.embed_content(
      model="models/text-embedding-004",
      content=section_text,
      task_type="SEMANTIC_SIMILARITY",
  )
  vector = result["embedding"]
  ```

### 3.5 ACM CCS 分類
- `ACM CCS/` 以下にある XML をパースしてタクソノミー辞書（`id`, `path`, `label`, `description`, `synonyms`）を構築し、JSON/SQLite としてキャッシュする。
- **候補抽出フェーズ**  
  - 要約の全文・セクション別要約・抽出キーフレーズを Sentence Transformers でエンコード。  
  - タクソノミー項目の `label + description` も同モデルでベクトル化し、コサイン類似度で上位 10〜15 件を候補として抽出。  
  - 候補には `score` と階層情報を付与し、LLM に渡す入力を生成する。
- **LLM 決定フェーズ**  
  - Few-shot プロンプトを用い、候補リストと論文情報を JSON フォーマットで提示。「必ず候補から選ぶ」「最大 3 件、不要なら none」などの制約を明記し、温度は 0〜0.2。  
  - 出力形式は `[{ "id": "...", "path": "...", "confidence": 0.84, "rationale": "..." }]` とし、形式エラー時はプロンプトを補正して再試行する。  
  - 追加で自己評価（例: “classification_confidence”: 0-1）や証拠となる語句の抜粋を求めると後検証に役立つ。
- **後処理**  
  - LLM の結果を `ccs_labels` テーブルに保存し、要約 JSON にも `ccs` フィールドとして追記。  
  - 同一論文に複数分類結果がある場合はタイムスタンプと評者（人手/LLMバージョン）を保持する。  
  - 低信頼度（閾値未満）の分類はレビュー待ちとしてフラグを立て、手動確認のワークフローに回す。
- **品質管理**  
  - 人手ラベルとの比較、LLM 自己評価、別モデル（例: GPT-4.1）によるクロスチェックで精度をモニタリング。  
  - 定期的に混同行列や F1 スコアを算出し、プロンプト/候補数/閾値調整の判断材料にする。

### 3.6 類似度計算と可視化
- 論文全体の代表ベクトル（セクション平均 or 重み付き和）と、セクション別ベクトルを両方保持し、`cosine(u, v) = (u·v)/(||u|| ||v||)` で類似度を算出する。SQL 例: `SELECT id, 1 - (embedding <=> normalize($1)) AS cosine_sim FROM embeddings WHERE section='overall' ORDER BY cosine_sim DESC LIMIT 20;`
- pgvector を使う場合、定期的に `ANALYZE` し、IVFFlat/IVFPQ インデックスを作成して検索速度を確保する。大規模化したら Faiss / Milvus / Pinecone などの外部ベクトルエンジンに切り替える計画を立てる。
- ターゲット論文を軸に、「近い（上位 K）」「やや離れている（順位帯で指定）」「関係が薄い（閾値以下）」を切り替えられる UI パラメータを設計し、API では `distance_bands=[{"name":"close","min":0.88},{"name":"medium","min":0.75,"max":0.88},...]` のような定義を返す。
- ACM CCS 概念や抽象カテゴリでフィルタリングし、`JOIN ccs_labels` によって同じ概念の論文を優先表示する。類似度スコアと CCS match スコアを組み合わせた複合スコア (`combined = 0.7*cosine + 0.3*ccs_overlap`) を計算してランキングに利用する。
- UI では類似度の閾値、セクション重み（例: 評価 40%, 目的 30%, 実装 30%）をリアルタイムに調整できるスライダーを提供し、変更時にはバックエンド API が再計算して返す。
- 「未カバー領域」のため、近傍距離の分布を解析して距離ギャップが大きい論文を提示するサジェスト機能を設ける（例: 距離が 0.6〜0.7 の論文をハイライト）。

### 3.7 インタラクティブ体験設計
- 直感的な操作感を目標に、要約カード・類似度スライダー・概念タグをドラッグやホバーで操作できる GUI を想定する。
- 「まだ語られていない領域を探る」ため、ターゲット論文から遠いが関係のある可能性が高い論文をハイライトする視覚表現（例: 距離に応じたカラーマップやアニメーション）を用意する。
- 類似度の観点（問題意識・目的・実装・評価）をタブやトグルで切り替え、視点ごとに関連論文がどのように変化するかを体感できるようにする。
- 探索の楽しさを高める仕掛けとして、ユーザが注目した論文をタイムラインやスタックに保存し、「巡った道筋」を振り返られるようにする。
- インタラクション設計の検証を行い、ユーザが望む情報に最短で辿り着けているか、発見体験が促進されているかを継続的に評価する。

### 3.8 UI 実装の土台
- バックエンドは REST/GraphQL API で要約データ・類似度計算・CCS 情報を提供し、非同期処理のためにジョブキューを導入する（例: Celery、RQ）。
- フロントエンドはリアクティブなフレームワーク（例: React + D3.js / Svelte / Vue）を採用し、類似度スライダーやグラフ表示を動的に更新できる構造を用意する。
- ベクトル検索との連携は、フロントからのクエリに対してバックエンドが類似度ランキングを返し、同時に CCS ラベルやメタデータも提供するレスポンス設計にする。
- UI コンポーネントは、ターゲット論文カード、セクション別類似度チャート、CCS フィルタ、距離マップ、探索ログタイムラインなどのモジュール化を行い、再利用性と開発効率を高める。
- 初期リリースではミニマムなビュー（ターゲット選択 + 類似リスト + CCS フィルタ）から着手し、ユーザテストの結果を反映しながら段階的にインタラクションを拡張する。
- 「自分の論文」と距離のある論文も含めて俯瞰できるよう、ターゲット論文を原点とした 2D/3D マップ（UMAP/MDS 等）を描画し、距離帯ごとに色・サイズを変えて表示する。ユーザはスライダーやチェックボックスで「遠い論文だけ表示」「近い論文を半透明にする」などの切り替えができるようにする。


## 4. データ保存・API 設計ガイド

### 4.1 データベース構成
- **推奨スタック**: PostgreSQL + pgvector 拡張を採用し、構造化データとベクトル類似度計算を同一基盤で扱う。大規模化を想定する場合は Milvus / Pinecone など専用ベクトル DB も検討。
- **コアテーブル**
  - `papers` : `id`, `title`, `authors`, `year`, `pdf_path`, `source_url`, `abstract`.
  - `summaries` : `paper_id`, `section`（overview/positioning/...）、`content`, `language`, `generated_at`, `quality_flag`.
  - `embeddings` : `paper_id`, `section`, `vector`(pgvector), `model`, `dim`, `normalized`.
  - `ccs_labels` : `paper_id`, `concept_id`, `concept_path`, `confidence`, `explanation`.
  - `processing_jobs` : 前処理ジョブのステータス・ログ（失敗時の再実行を想定）。
- **補助ビュー**
  - セクション別類似度のキャッシュを `materialized view` として保持し、フロントの初回読み込みを高速化。
  - 「カバーされていない領域」指標のため、近傍距離の分布を集約した統計テーブルを定期更新。

### 4.2 API 設計
- **REST エンドポイント例**
  - `GET /papers` : ページネーション付き一覧。検索パラメータ（年、著者、CCS 概念）をサポート。
  - `GET /papers/{id}` : 論文の概要・要約セクション・CCS ラベル・近傍リンクをまとめて返す。
  - `POST /search/similarity` : `paper_id` または `sections` テキストを入力に、上位 K 件の類似論文とセクション別スコアを返す。
  - `POST /search/explore` : ターゲット論文と距離帯（近い/中間/遠い）を指定し、各クラスタの代表論文を返す。
  - `GET /ccs/concepts` : ACM CCS の階層構造を返し、フロントでフィルタ UI を構築できるようにする。
- **レスポンス設計**
  - 類似検索の返却では、`similarity_overall`, `similarity_by_section`, `ccs_overlap`, `distance_band` などを含めて UI が直感的に利用できる値を提供。
  - キャッシュ可能なメタデータ（タイトル、著者、要約短文）は CDN やフロントの IndexedDB に保存し、重複リクエストを減らす。

### 4.3 前処理とオンライン処理の分離
- すべての PDF は事前バッチで要約・埋め込み・CCS 分類まで完了させ、DB には確定済みのデータのみ保存する。
- 前処理パイプラインはスケジューラ（Airflow, Prefect など）で定期実行し、成果物を DB に反映するまでを原子単位で行う。
- フロントエンドは既存 DB/API から結果を引くだけに留め、オンライン処理（リアルタイム LLM 呼び出し）は Future Work として切り出す。
- 将来的にユーザアップロードや追加論文比較をサポートする場合は、別キューで前処理を走らせたのち、承認後に本番 DB にマージする。

## 4. データ管理とツール運用
- `.env` に OpenAI / Gemini / Vertex などの API キーを管理し、コミット対象から除外する。
- 生成物（要約 JSON、埋め込みファイル、分類結果）はバージョン管理または日付付きディレクトリで整理する。
- 大量処理時はバッチ実行スクリプトとリトライ機構を用意して、途中中断しても再開しやすくする。

## 5. 品質保証と検証
- 抽出テキストと要約のサンプルレビューを行い、情報落ちや誤変換をチェックする。
- 埋め込み類似度のトップ結果を人間が確認し、期待する近さ/遠さになっているか定期的に評価する。
- ACM CCS 分類の出力を専門家の目でスポットチェックし、誤分類が続く場合はプロンプトや候補抽出ロジックを調整する。

## 6. 未決定事項と検討タスク
- Gemini 以外の埋め込みモデルをどこまで許容するか（利用料金や速度とのトレードオフ）。
- UI の具体的な可視化方法（リスト、グラフ、ネットワーク図など）と操作パターン。
- 類似度の閾値・重み付けの標準値、およびユーザがカスタマイズした設定の保存方法。
- 長期運用時のストレージ戦略、ログの保持期間、モデル更新のスケジュール。
